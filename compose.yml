name: playground

x-deps: &deps
  deploy:
    resources:
      limits:
        memory: 256m # defaulted memory limit to 256mb
  restart: unless-stopped

services:
  postgres:
    <<: *deps
    image: docker.io/postgres:latest
    ports:
      - 5432:5432
    environment:
      POSTGRES_DB: playground_app
      POSTGRES_USER: local
      POSTGRES_PASSWORD: local
    volumes:
      - ${LOCAL_WORKSPACE_FOLDER:-.}/.docker/postgres/migrations:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d postgres -U local"]
      interval: 1s
      timeout: 5s
      retries: 5
    
  mongo:
    <<: *deps
    image: docker.io/mongo:latest
    ports:
      - 27017:27017
    restart: unless-stopped
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: root
      MONGO_INITDB_DATABASE: saga
    volumes:
      - ${LOCAL_WORKSPACE_FOLDER:-.}/.docker/mongo/init.js:/docker-entrypoint-initdb.d/init.js:ro

  redis:
    <<: *deps
    image: docker.io/redis:6.2-alpine
    command: redis-server --requirepass local
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD-SHELL", "redis-cli ping"]

  rabbitmq:
    <<: *deps
    image: docker.io/rabbitmq:3.13-management
    container_name: rabbitmq
    restart: unless-stopped
    ports:
      - 5672:5672
      - 15672:15672

  proxy:
    image: docker.io/nginx:alpine-otel
    container_name: proxy
    restart: unless-stopped
    depends_on:
      app-go-server:
        condition: service_healthy
    ports:
      - 8089:80
    volumes:
      - ${LOCAL_WORKSPACE_FOLDER-.}/.docker/nginx/conf.d/:/etc/nginx/conf.d/
      - ${LOCAL_WORKSPACE_FOLDER-.}/.docker/nginx/nginx.conf:/etc/nginx/nginx.conf

  grafana:
    <<: *deps
    image: docker.io/grafana/grafana
    container_name: grafana
    restart: unless-stopped
    environment:
      GF_LOG_LEVEL: debug
      GF_AUTH_ANONYMOUS_ENABLED: true
      GF_AUTH_ANONYMOUS_ORG_ROLE: Admin
      GF_AUTH_DISABLE_LOGIN_FORM: true
    ports:
      - "10000:3000"
    volumes:
      - ${LOCAL_WORKSPACE_FOLDER:-.}/.docker/grafana/provisioning:/etc/grafana/provisioning

  monitoring-prometheus:
    <<: *deps
    image: docker.io/prom/prometheus
    container_name: monitoring-prometheus
    restart: unless-stopped
    pull_policy: missing
    ports:
      - 10001:9090
    volumes:
      - ${LOCAL_WORKSPACE_FOLDER:-.}/.docker/prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      [
        "--config.file=/etc/prometheus/prometheus.yml",
        "--storage.tsdb.path=/prometheus",
        "--web.console.libraries=/etc/prometheus/console_libraries",
        "--web.console.templates=/etc/prometheus/consoles",
        "--web.enable-remote-write-receiver",
        "--web.enable-lifecycle",
        "--web.enable-otlp-receiver",
        "--web.route-prefix=/",
        "--enable-feature=examplar-storage",
      ]

  monitoring-otel-collector:
    # <<: *deps
    image: docker.io/otel/opentelemetry-collector-contrib:0.115.1
    container_name: monitoring-otel-collector
    command: ["--config", "/etc/otelcollector/otelcollector.yml"]
    volumes:
      - ${LOCAL_WORKSPACE_FOLDER:-./}/.docker/otelcollector:/etc/otelcollector
    ports:
      - 1888:1888 # pprof extension
      - 8888:8888 # Prometheus metrics exposed by the Collector
      - 8889:8889 # Prometheus exporter metrics
      - 13133:13133 # health_check extension
      - 4317:4317 # OTLP gRPC receiver
      - 10002:4317 # OTLP gRPC receiver
      - 4318:4318 # OTLP http receiver
      - 55679:55679 # zpages extension

  monitoring-tempo:
    # <<: *deps
    container_name: monitoring-tempo
    image: docker.io/grafana/tempo:main-13885de
    command: ["-config.file=/etc/tempo.yml"]
    volumes:
      - ${LOCAL_WORKSPACE_FOLDER:-.}/.docker/tempo.yml:/etc/tempo.yml

  # ref: https://github.com/google/cadvisor/issues/3187
  # this is to scrape docker stats' "metrics"
  cadvisor:
    <<: *deps
    image: gcr.io/cadvisor/cadvisor:v0.47.1
    container_name: cadvisor
    privileged: true # stops oom warning
    platform: linux/aarch64 # m1/m2 mac
    devices:
      - /dev/kmsg:/dev/kmsg
    volumes:
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /etc/machine-id:/etc/machine-id:ro
      - /var/lib/dbus/machine-id:/var/lib/dbus/machine-id:ro

  app-go-server:
    build:
      context: .
      dockerfile: app-go/Dockerfile
    # x-develop:
    #   watch:
    #     - action: rebuild
    #       path: ./app-go
    image: playground-app-go:local
    command: /app-go serve
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      DB_CONN: host=postgres user=local password=local dbname=playground_app port=5432 sslmode=disable
      HTTP_ADDRESS: 0.0.0.0:80
      OTEL_EXPORTER_OTLP_ENDPOINT: http://monitoring-otel-collector:4317
      OTEL_EXPORTER_OTLP_PROTOCOL: grpc
      OTEL_EXPORTER_OTLP_TIMEOUT: 5000
      OTEL_EXPORTER_OTLP_COMPRESSION: gzip
      OTEL_RESOURCE_ATTRIBUTES: service.namespace=playground
      OTEL_SERVICE_NAME: app-go-server
      OTEL_TRACES_SAMPLER: always_on
      RABBIT_URI: amqp://guest:guest@rabbitmq:5672/
      REDIS_URI: redis://:local@redis:6379/0
    deploy:
      # replicas: 3
      resources:
        limits:
          memory: 512m # defaulted memory limit to 512mb
    healthcheck:
      test:
        [
          "CMD",
          "/wget",
          "--quiet",
          "--output-document=-",
          "http://0.0.0.0:80/health",
        ]

  app-go-worker:
    build:
      context: .
      dockerfile: app-go/Dockerfile
    # x-develop:
    #   watch:
    #     - action: rebuild
    #       path: ./app-go
    image: playground-app-go:local
    container_name: app-go-worker
    command: /app-go work
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      DB_CONN: host=postgres user=local password=local dbname=playground_app port=5432 sslmode=disable
      HTTP_ADDRESS: 0.0.0.0:80
      OTEL_EXPORTER_OTLP_ENDPOINT: http://monitoring-otel-collector:4317
      OTEL_EXPORTER_OTLP_PROTOCOL: grpc
      OTEL_EXPORTER_OTLP_TIMEOUT: 5000
      OTEL_RESOURCE_ATTRIBUTES: service.namespace=playground
      OTEL_SERVICE_NAME: app-go-worker
      OTEL_TRACES_SAMPLER: always_on
      RABBIT_URI: amqp://guest:guest@rabbitmq:5672/
      REDIS_URI: redis://:local@redis:6379/0
    deploy:
      resources:
        limits:
          memory: 512m # defaulted memory limit to 512mb
    healthcheck:
      test:
        [
          "CMD",
          "/wget",
          "--quiet",
          "--output-document=-",
          "http://0.0.0.0:80/health",
        ]

  app-java-server:
    build:
      context: .
      dockerfile: app-java/Dockerfile
    image: playground-app-java:local
    container_name: app-java-server
    depends_on:
      postgres:
        condition: service_healthy
    ports:
      - "8081:80"
    healthcheck:
      test:
        [
          "CMD",
          "/wget",
          "--quiet",
          "--output-document=-",
          "http://0.0.0.0:80/health",
        ]

  # broker:
  #   build:
  #     context: ./broker
  #     dockerfile: Dockerfile
  #     target: dev # specify "dev" stage to run
  #   image: broker:local
  #   container_name: broker
  #   ports:
  #     - "4000:4000"
  #   command: /home/app/broker/bin/broker
  #   environment:
  #     OTEL_EXPORTER_OTLP_ENDPOINT: http://monitoring-otel-collector:4317
  #     OTEL_SERVICE_NAME: broker

  k6:
    image: docker.io/grafana/k6:latest
    container_name: k6
    command: run /scenarios/scenario-0.js
    depends_on:
      proxy:
        condition: service_started
    restart: no
    environment:
      - API_HOST=http://proxy
    volumes:
      - ${LOCAL_WORKSPACE_FOLDER:-.}/k6/scenarios:/scenarios
 